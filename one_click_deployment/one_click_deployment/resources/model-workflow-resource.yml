new_cluster: &new_cluster
  new_cluster:
    num_workers: 3
    spark_version: 15.3.x-cpu-ml-scala2.12
    node_type_id: i3.xlarge
    data_security_mode: "SINGLE_USER"
    custom_tags:
      clusterSource: mlops-stacks_0.4

common_permissions: &permissions
  permissions:
    - level: CAN_VIEW
      group_name: users

resources:
  jobs:
    model_training_job:
      name: ${bundle.target}-one_click_deployment-model-training-job
      job_clusters:
        - job_cluster_key: model_training_job_cluster
          <<: *new_cluster
      tasks:
        - task_key: Train
          job_cluster_key: model_training_job_cluster
          notebook_task:
            notebook_path: ../training/notebooks/Train.py
            base_parameters:
              env: ${bundle.target}
              experiment_name: ${var.experiment_name}
              model_name: ${var.catalog_name}.one_click_deployment.${var.model_name}
              # git source information of current ML resource deployment. It will be persisted as part of the workflow run
              git_source_info: url:${bundle.git.origin_url}; branch:${bundle.git.branch}; commit:${bundle.git.commit}
          
        - task_key: ModelValidation
          job_cluster_key: model_training_job_cluster
          depends_on:
            - task_key: Train
          notebook_task:
            notebook_path: ../validation/notebooks/ModelValidation.py
            base_parameters:
              experiment_name: ${var.experiment_name}
              # The `run_mode` defines whether model validation is enabled or not.
              # It can be one of the three values:
              # `disabled` : Do not run the model validation notebook.
              # `dry_run`  : Run the model validation notebook. Ignore failed model validation rules and proceed to move
              #               model to Production stage.
              # `enabled`  : Run the model validation notebook. Move model to Production stage only if all model validation
              #               rules are passing.
              run_mode: enabled
              # Whether to load the current registered "Production" stage model as baseline.
              # Baseline model is a requirement for relative change and absolute change validation thresholds.
              enable_baseline_comparison: "false"
              # Evaluation dataset path for GenAI evaluation
              validation_input: SELECT * FROM delta.`${var.catalog_name}.${var.schema_name}.eval_dataset`
              # Model type for text generation models
              model_type: text-generation
              # Target column for evaluation (not used for GenAI evaluation)
              targets: expected_output
              # Specifies the name of the function in one_click_deployment/training_validation_deployment/validation/validation.py that returns custom metrics.
              # TODO(optional): custom_metrics_loader_function
              custom_metrics_loader_function: custom_metrics
              # Specifies the name of the function in one_click_deployment/training_validation_deployment/validation/validation.py that returns model validation thresholds.
              # TODO(optional): validation_thresholds_loader_function
              validation_thresholds_loader_function: validation_thresholds
              # Specifies the name of the function in one_click_deployment/training_validation_deployment/validation/validation.py that returns evaluator_config.
              # TODO(optional): evaluator_config_loader_function
              evaluator_config_loader_function: evaluator_config
              # git source information of current ML resource deployment. It will be persisted as part of the workflow run
              git_source_info: url:${bundle.git.origin_url}; branch:${bundle.git.branch}; commit:${bundle.git.commit}
        - task_key: ModelDeployment
          job_cluster_key: model_training_job_cluster
          depends_on:
            - task_key: ModelValidation
          notebook_task:
            notebook_path: ../deployment/model_deployment/notebooks/ModelDeployment.py
            base_parameters:
              env: ${bundle.target}
              # git source information of current ML resource deployment. It will be persisted as part of the workflow run
              git_source_info: url:${bundle.git.origin_url}; branch:${bundle.git.branch}; commit:${bundle.git.commit}
      # Trigger on PR to main branch - configured via Git integration
      # schedule:
      #   quartz_cron_expression: "0 0 9 * * ?" # daily at 9am
      #   timezone_id: UTC
      
      # Git trigger configuration (requires Databricks Git integration setup)
      git_source:
        git_url: ${bundle.git.origin_url}
        git_provider: gitHub  # or gitLab, azureDevOpsServices, etc.
        git_branch: main
      
      trigger:
        # Trigger when PR is merged to main branch
        file_arrival:
          url: ${bundle.git.origin_url}
          # This would be configured in the Databricks UI or via API
          # to trigger on PR merge events
      <<: *permissions
      # If you want to turn on notifications for this job, please uncomment the below code,
      # and provide a list of emails to the on_failure argument.
      #
      #  email_notifications:
      #    on_failure:
      #      - first@company.com
      #      - second@company.com
